{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pix2Pix modeling\n",
    "\n",
    "Model repo: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1611.07004.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data, img_as_float, img_as_ubyte, io, color\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_mse\n",
    "from cellvision_lib import get_model_data_splits\n",
    "# %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 500 images for channel 1\n",
      "At path /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_500\n",
      "Removing files at /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_500\n",
      "Done removing files.\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n",
      "Setting up 500 images for channel 2\n",
      "At path /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2_500\n",
      "Removing files at /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2_500\n",
      "Done removing files.\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n",
      "Setting up 500 images for channel 3\n",
      "At path /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel3_500\n",
      "Removing files at /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel3_500\n",
      "Done removing files.\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n",
      "Setting up 500 images for channel 4\n",
      "At path /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel4_500\n",
      "Removing files at /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel4_500\n",
      "Done removing files.\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n",
      "Setting up 500 images for channel 5\n",
      "At path /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel5_500\n",
      "Removing files at /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel5_500\n",
      "Done removing files.\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n"
     ]
    }
   ],
   "source": [
    "# Proprocesing the data for pix2pix model\n",
    "import os\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "MAX_DEPTH = 100\n",
    "NUM_SAMPLES = 109\n",
    "\n",
    "# folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized'\n",
    "# train, test, val = train_test_val(folder_path, channels = 1, train_pp = .67, test_pp = .165, val_pp = .165, set_seed = 1)\n",
    "\n",
    "# train[0:10]\n",
    "\n",
    "def clear_test_files(pix2pix_path):\n",
    "    print('Removing files at ' + pix2pix_path)\n",
    "    outer_paths = ['A','B']\n",
    "    inner_paths = ['test','train','val']\n",
    "    for outer in outer_paths:\n",
    "        for inner in inner_paths:\n",
    "            files = glob.glob('{root}/{split}/{inner}/*'.format(root=pix2pix_path, split=outer, inner=inner))\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "    print('Done removing files.')\n",
    "                \n",
    "def isolate_test_samples(train, val, test):\n",
    "    num_test = len(test)\n",
    "    train_new = []\n",
    "    val_new = []\n",
    "    test_name = []\n",
    "    \n",
    "    for low, ref in train:\n",
    "        fname = os.path.basename(comp)\n",
    "        end_sample_prefix_index = fname.find('_channel{}_z'.format(channel)) \n",
    "        start_z_index = end_sample_prefix_index + 11\n",
    "        end_index = fname.find('.tif') \n",
    "        sample_prefix = fname[0:end_sample_prefix_index]\n",
    "                \n",
    "def setup_images_for_pix2pix(src_path, channel, num_images):\n",
    "    print(\"Setting up {} images for channel {}\".format(num_images, channel))\n",
    "    pix_folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel{}_{}'.format(channel,num_images)\n",
    "    print(\"At path \" + pix_folder_path)\n",
    "    clear_test_files(pix_folder_path)\n",
    "    train, test, val = get_model_data_splits(src_path, \n",
    "                                      channel = channel, \n",
    "                                      train_pp = .67, \n",
    "                                      test_pp = .165, \n",
    "                                      val_pp = .165, \n",
    "                                      seed = 1)\n",
    "\n",
    "    train_images = train[0:num_images]\n",
    "    test_images = test[0:num_images]\n",
    "    val_images = val[0:num_images]\n",
    "    \n",
    "    def get_pix_fname(base_dir, ref_fname, _channel, mode):\n",
    "        fname = os.path.basename(comp)\n",
    "        end_sample_prefix_index = fname.find('_channel{}_z'.format(channel)) \n",
    "        start_z_index = end_sample_prefix_index + 11\n",
    "        end_index = fname.find('.tif') \n",
    "        sample_prefix = fname[0:end_sample_prefix_index]\n",
    "        z_depth = fname[start_z_index:end_index]\n",
    "        new_comp_path = '{}/A/{}/{}_channel{}_z{}.jpg'.format(base_dir, mode, sample_prefix, _channel, z_depth)\n",
    "        new_ref_path = '{}/B/{}/{}_channel{}_z{}.jpg'.format(base_dir, mode, sample_prefix, _channel, z_depth)\n",
    "        if not os.path.exists('{}/A/{}'.format(base_dir,mode)):\n",
    "            os.makedirs('{}/A/{}'.format(base_dir,mode))\n",
    "        if not os.path.exists('{}/B/{}'.format(base_dir,mode)):\n",
    "            os.makedirs('{}/B/{}'.format(base_dir,mode))\n",
    "        return new_comp_path, new_ref_path\n",
    "    \n",
    "    for i, (comp, ref) in enumerate(train_images):\n",
    "        new_comp_path, new_ref_path = get_pix_fname(pix_folder_path, ref, channel, \"train\")\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "        \n",
    "    print(\"done with training images\")\n",
    "    \n",
    "    for i, (comp, ref) in enumerate(test_images):\n",
    "        new_comp_path, new_ref_path = get_pix_fname(pix_folder_path, ref, channel, \"test\")\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "        \n",
    "    print(\"done with testing images\")\n",
    "        \n",
    "    for i, (comp, ref) in enumerate(val_images):\n",
    "        new_comp_path, new_ref_path = get_pix_fname(pix_folder_path, ref, channel, \"val\")\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "        \n",
    "    print(\"done with validation images\")\n",
    "\n",
    "\n",
    "folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-top50'\n",
    "# folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized'\n",
    "\n",
    "setup_images_for_pix2pix(folder_path, 1, 500)\n",
    "setup_images_for_pix2pix(folder_path, 2, 500)\n",
    "setup_images_for_pix2pix(folder_path, 3, 500)\n",
    "setup_images_for_pix2pix(folder_path, 4, 500)\n",
    "setup_images_for_pix2pix(folder_path, 5, 500)\n",
    "\n",
    "# print()\n",
    "# print(glob.glob('/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1/A/train/*'))\n",
    "# print()\n",
    "# print(glob.glob('/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1/B/train/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Commands to run with the pix2pix framework\n",
    "\n",
    "python datasets/combine_A_and_B.py --fold_A /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/A --fold_B /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/B --fold_AB /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing --num_imgs 200\n",
    "\n",
    "python datasets/combine_A_and_B.py --fold_A /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_1000/A --fold_B /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_1000/B --fold_AB /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_1000 --num_imgs 1000\n",
    "bsub -o fold_1_1000.txt python datasets/combine_A_and_B.py --fold_A /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2_1000/A --fold_B /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2_1000/B --fold_AB /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2_1000 --num_imgs 1000\n",
    "bsub -o fold_1_1000.txt python datasets/combine_A_and_B.py --fold_A /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel3_1000/A --fold_B /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel3_1000/B --fold_AB /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel3_1000 --num_imgs 1000\n",
    "bsub -o fold_1_1000.txt python datasets/combine_A_and_B.py --fold_A /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel4_1000/A --fold_B /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel4_1000/B --fold_AB /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel4_1000 --num_imgs 1000\n",
    "bsub -o fold_1_1000.txt python datasets/combine_A_and_B.py --fold_A /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel5_1000/A --fold_B /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel5_1000/B --fold_AB /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel5_1000 --num_imgs 1000\n",
    "\n",
    "\n",
    "bsub -Is -gpu \"num=1:mode=exclusive_process:mps=yes\" python train.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1 --name cellvision_channel1_100 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o jobout.tx python train.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2 --name cellvision_channel2_100 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o channel1_1000_jobout.txt python train.py --save_epoch_freq 25 --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_1000 --name cellvision_channel1_1000 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o channel2_1000_jobout.txt python train.py --save_epoch_freq 25 --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2_1000 --name cellvision_channel2_1000 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o channel3_1000_jobout.txt python train.py --save_epoch_freq 25 --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel3_1000 --name cellvision_channel3_1000 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o channel4_1000_jobout.txt python train.py --save_epoch_freq 25 --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel4_1000 --name cellvision_channel4_1000 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o channel5_1000_jobout.txt python train.py --save_epoch_freq 25 --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel5_1000 --name cellvision_channel5_1000 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o channeltesting_jobout.txt python train.py --save_epoch_freq 25 --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_1000 --name cellvision_testing --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "\n",
    "\n",
    "export CHANNEL=4\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" -o \"$CHANNEL_jobout.txt\" python train.py --dataroot \"/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel$CHANNEL\" --name \"cellvision_$CHANNEL_100\" --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "\n",
    "bsub -Is -gpu \"num=1:mode=exclusive_process:mps=yes\" python test.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_1000 --name cellvision_channel1_1000 --model pix2pix --direction AtoB --num_test 100\n",
    "bsub -Is -gpu \"num=1:mode=exclusive_process:mps=yes\" python test.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel2_1000 --name cellvision_channel2_1000 --model pix2pix --direction AtoB --num_test 100\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" python test.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel3_1000 --name cellvision_channel3_1000 --model pix2pix --direction AtoB --num_test 100\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" python test.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel4_1000 --name cellvision_channel4_1000 --model pix2pix --direction AtoB --num_test 100\n",
    "bsub -gpu \"num=1:mode=exclusive_process:mps=yes\" python test.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel5_1000 --name cellvision_channel5_1000 --model pix2pix --direction AtoB --num_test 100\n",
    "\n",
    "\n",
    "bsub -Is -gpu \"num=1:mode=exclusive_process:mps=yes\" python test.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1 --name cellvision5 --model pix2pix --direction AtoB\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "channels = list(range(1,6))\n",
    "sample_sizes =[100, 1000]\n",
    "\n",
    "result_path = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results'\n",
    "\n",
    "results_dirs = []\n",
    "mses = []\n",
    "ssims = []\n",
    "for sample_size in sample_sizes:\n",
    "    sub_results = []\n",
    "    mses_sub = []\n",
    "    ssim_sub = []\n",
    "    for channel in channels:\n",
    "        print(\"Getting MSE and SSIM for sample size {} and channel {}\".format(sample_size, channel))\n",
    "        result_dir = '{}/cellvision_channel{}_{}/test_latest/images'.format(result_path, channel, sample_size)\n",
    "        real_path_low = '{}/*_real_A.png'.format(result_dir)\n",
    "        real_low_imgs = glob.glob(real_path_low)\n",
    "        print(\"getting {} images\".format(len(real_low_imgs)))\n",
    "        channel_mse = []\n",
    "        channel_ssim = []\n",
    "        for real_path_low in real_low_imgs:\n",
    "            fname = os.path.basename(real_path_low)\n",
    "            fname_prefix = fname[:-11]\n",
    "            real_path_high = '{}/{}_real_B.png'.format(result_dir, fname_prefix)\n",
    "            fake_path = '{}/{}_fake_B.png'.format(result_dir, fname_prefix)\n",
    "            try:\n",
    "                real_img_high = color.rgb2gray(io.imread(real_path_high).astype(np.uint))\n",
    "                real_img_low = color.rgb2gray(io.imread(real_path_low).astype(np.uint))\n",
    "                fake_img = color.rgb2gray(io.imread(fake_path).astype(np.uint))\n",
    "            except OSError:\n",
    "                print(\"OSERROR skipping \" + fake_path)\n",
    "            \n",
    "            _min = real_img_high.min()\n",
    "            _max = real_img_high.max()\n",
    "\n",
    "            low_high_ssim = compare_ssim(real_img_low, real_img_high, data_range=_max-_min)\n",
    "            fake_high_ssim = compare_ssim(fake_img, real_img_high, data_range=_max-_min)\n",
    "            channel_ssim.append( (low_high_ssim,fake_high_ssim) )\n",
    "\n",
    "            low_high_mse = compare_mse(real_img_low, real_img_high)\n",
    "            fake_high_mse = compare_mse(fake_img, real_img_high)\n",
    "            channel_mse.append( (low_high_mse,fake_high_mse) )\n",
    "        \n",
    "        mses_sub.append(channel_mse)\n",
    "        ssim_sub.append(channel_ssim)\n",
    "    mses.append(mses_sub)\n",
    "    ssims.append(ssim_sub)\n",
    "\n",
    "print(len(mses[0][0][0]))\n",
    "# results_dir = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision5/test_latest/images'\n",
    "\n",
    "# out_imgs = glob.glob(results_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ssims))\n",
    "print(len(ssims[0]))\n",
    "print(len(ssims[0][0]))\n",
    "ssims[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "low_means = []\n",
    "fake_means = []\n",
    "for sample_size in ssims:\n",
    "    for channel in sample_size:\n",
    "        low = [ssim[0] for ssim in channel]\n",
    "        print(len(low))\n",
    "        low_std = statistics.stdev(low)\n",
    "        low_mean = statistics.mean(low)\n",
    "        print(low_mean)\n",
    "        low_means.append(low_mean)\n",
    "\n",
    "        fake = [ssim[1] for ssim in channel]\n",
    "        fake_std = statistics.stdev(fake)\n",
    "        fake_mean = statistics.mean(fake)\n",
    "        fake_means.append(fake_mean)\n",
    "\n",
    "\n",
    "print(\"Low ssim mean {} with std {}\".format(low_mean,low_std))\n",
    "print(\"Fake ssim mean {} with std {}\".format(fake_mean,fake_std))\n",
    "\n",
    "# low_mse = [mse[0] for mse in mses]\n",
    "# low_std_mse = statistics.stdev(low_mse)\n",
    "# low_mean_mse = statistics.mean(low_mse)\n",
    "\n",
    "# fake_mse = [mse[1] for mse in mses]\n",
    "# fake_std_mse = statistics.stdev(fake_mse)\n",
    "# fake_mean_mse = statistics.mean(fake_mse)\n",
    "# print()\n",
    "# print(\"Low mse mean {} with std {}\".format(low_mean_mse,low_std_mse))\n",
    "# print(\"Fake mse mean {} with std {}\".format(fake_mean_mse,fake_std_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing MSE for denoising\n",
    "plt.plot(list(range(1, 6)), low_means[0:5], label=\"100 Sample Size No Transformation\", color='blue') \n",
    "plt.plot(list(range(1, 6)), fake_means[0:5], label=\"100 Sample Size Prediction\", color='red') \n",
    "plt.plot(list(range(1, 6)), low_means[5:10], label=\"1000 Sample Size No Transformation\", color='purple') \n",
    "plt.plot(list(range(1, 6)), fake_means[5:10], label=\"1000 Sample Size Prediction\", color='green') \n",
    "\n",
    "plt.title('Comparing SSIM For Pix2Pix Model')\n",
    "plt.legend(loc = 'lower right')\n",
    "# plt.ylim([0, 1])\n",
    "plt.xlim([1, 5])\n",
    "plt.axes().set_xticks(list(range(1, 6)), minor=False)\n",
    "\n",
    "plt.ylabel('SSIM')\n",
    "plt.xlabel('Channel (larger number -> higher laser intensity)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing images\n",
    "from skimage import exposure\n",
    "path_to_data = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision_channel1_1000/test_latest/images/sample112_channel1_z34_real_A.png'\n",
    "imsk_A = io.imread(path_to_data)\n",
    "imsk_A = exposure.rescale_intensity(imsk_A,in_range=(0,np.max(imsk_A)))\n",
    "path_to_data = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision_channel1_1000/test_latest/images/sample112_channel1_z34_real_B.png'\n",
    "imsk_B = io.imread(path_to_data)\n",
    "imsk_B = exposure.rescale_intensity(imsk_B,in_range=(0,np.max(imsk_B)))\n",
    "path_to_data = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision_channel1_1000/test_latest/images/sample112_channel1_z34_fake_B.png'\n",
    "fake = io.imread(path_to_data)\n",
    "fake = exposure.rescale_intensity(fake,in_range=(0,np.max(fake)))\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(25,5))\n",
    "# ax[0].imshow(imsk_nl[0]);\n",
    "ax[0].imshow(imsk_A);\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(imsk_B);\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(fake);\n",
    "ax[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision_channel1_1000/test_latest/images/sample112_channel1_z34_real_A.png'\n",
    "imsk_A = io.imread(path_to_data)\n",
    "imsk_A = exposure.rescale_intensity(imsk_A,in_range=(0,np.max(imsk_A)))\n",
    "path_to_data = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision_channel1_1000/test_latest/images/sample112_channel1_z34_real_B.png'\n",
    "imsk_B = io.imread(path_to_data)\n",
    "imsk_B = exposure.rescale_intensity(imsk_B,in_range=(0,np.max(imsk_B)))\n",
    "path_to_data = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1_1000/test/sample61_channel1_z48.jpg'\n",
    "fake = io.imread(path_to_data)\n",
    "fake = exposure.rescale_intensity(fake,in_range=(0,np.max(fake)))\n",
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=(25,5))\n",
    "# ax[0].imshow(imsk_nl[0]);\n",
    "ax[0].imshow(imsk_A);\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(imsk_B);\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(fake);\n",
    "ax[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision_channel1_1000/test_latest/images/sample27_channel1_z26_real_A.png'\n",
    "path_to_data_B = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision_channel1_1000/test_latest/images/sample27_channel1_z26_real_B.png'\n",
    "\n",
    "imsk_A = io.imread(path_to_data)\n",
    "imsk_B = io.imread(path_to_data_B)\n",
    "_min = imsk_A.min()\n",
    "_max = imsk_A.max()\n",
    "\n",
    "low_high_ssim = compare_ssim(imsk_A, real_img_high, data_range=_max-_min)\n",
    "low_high_ssim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
