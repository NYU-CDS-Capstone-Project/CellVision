{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pix2Pix modeling\n",
    "\n",
    "Model repo: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1611.07004.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data, img_as_float, img_as_ubyte, io, color\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_mse\n",
    "from cellvision_lib import train_test_val\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 100 images for channel 2\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n",
      "Setting up 100 images for channel 3\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n",
      "Setting up 100 images for channel 4\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n",
      "Setting up 100 images for channel 5\n",
      "done with training images\n",
      "done with testing images\n",
      "done with validation images\n"
     ]
    }
   ],
   "source": [
    "# Proprocesing the data for pix2pix model\n",
    "import os\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "MAX_DEPTH = 100\n",
    "NUM_SAMPLES = 109\n",
    "\n",
    "# folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized'\n",
    "# train, test, val = train_test_val(folder_path, channels = 1, train_pp = .67, test_pp = .165, val_pp = .165, set_seed = 1)\n",
    "\n",
    "# train[0:10]\n",
    "\n",
    "def clear_test_files(pix2pix_path):\n",
    "    outer_paths = ['A','B']\n",
    "    inner_paths = ['test','train','val']\n",
    "    for outer in outer_paths:\n",
    "        for inner in inner_paths:\n",
    "            files = glob.glob('{root}/{split}/{inner}/*'.format(root=pix2pix_path, split=outer, inner=inner))\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "                \n",
    "def setup_images_for_pix2pix(src_path, channel, num_images):\n",
    "    print(\"Setting up {} images for channel {}\".format(num_images, channel))\n",
    "    pix_folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel{}_{}'.format(channel,num_images)\n",
    "    print(\"At path \" + pix_folder_path)\n",
    "    clear_test_files(pix_folder_path)\n",
    "    train, test, val = train_test_val(src_path, \n",
    "                                      channels = channel, \n",
    "                                      train_pp = .67, \n",
    "                                      test_pp = .165, \n",
    "                                      val_pp = .165, \n",
    "                                      set_seed = 1)\n",
    "\n",
    "    train_images = train[0:num_images]\n",
    "    test_images = test[0:num_images]\n",
    "    val_images = val[0:num_images]\n",
    "    \n",
    "    def get_pix_fname(base_dir, ref_fname, _channel):\n",
    "        fname = os.path.basename(comp)\n",
    "        end_sample_prefix_index = fname.find('_channel{}_z'.format(channel)) \n",
    "        start_z_index = end_sample_prefix_index + 11\n",
    "        end_index = fname.find('.tif') \n",
    "        sample_prefix = fname[0:end_sample_prefix_index]\n",
    "        z_depth = fname[start_z_index:end_index]\n",
    "        new_comp_path = '{}/A/train/{}_channel{}_z{}.jpg'.format(base_dir, sample_prefix, _channel, z_depth)\n",
    "        new_ref_path = '{}/B/train/{}_channel{}_z{}.jpg'.format(base_dir, sample_prefix, _channel, z_depth)\n",
    "        if not os.path.exists('{}/A/train'.format(base_dir)):\n",
    "            os.makedirs('{}/A/train'.format(base_dir))\n",
    "        if not os.path.exists('{}/B/train'.format(base_dir)):\n",
    "            os.makedirs('{}/B/train'.format(base_dir))\n",
    "        return new_comp_path, new_ref_path\n",
    "    \n",
    "    for i, (comp, ref) in enumerate(train_images):\n",
    "        new_comp_path, new_ref_path = get_pix_fname(pix_folder_path, ref, channel)\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "        \n",
    "    print(\"done with training images\")\n",
    "    \n",
    "    for i, (comp, ref) in enumerate(test_images):\n",
    "        new_comp_path, new_ref_path = get_pix_fname(pix_folder_path, ref, channel)\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "        \n",
    "    print(\"done with testing images\")\n",
    "        \n",
    "    for i, (comp, ref) in enumerate(val_images):\n",
    "        new_comp_path, new_ref_path = get_pix_fname(pix_folder_path, ref, channel)\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "        \n",
    "    print(\"done with validation images\")\n",
    "\n",
    "\n",
    "folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-top50'\n",
    "# folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized'\n",
    "\n",
    "# setup_images_for_pix2pix(folder_path, 1, 100)\n",
    "setup_images_for_pix2pix(folder_path, 2, 100)\n",
    "setup_images_for_pix2pix(folder_path, 3, 100)\n",
    "setup_images_for_pix2pix(folder_path, 4, 100)\n",
    "setup_images_for_pix2pix(folder_path, 5, 100)\n",
    "\n",
    "# print()\n",
    "# print(glob.glob('/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1/A/train/*'))\n",
    "# print()\n",
    "# print(glob.glob('/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/channel1/B/train/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Commands to run with the pix2pix framework\n",
    "\n",
    "python datasets/combine_A_and_B.py --fold_A /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/A --fold_B /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/B --fold_AB /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing --num_imgs 200\n",
    "\n",
    "bsub -Is -gpu \"num=1:mode=exclusive_process:mps=yes\" python train.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing --name cellvision5 --model pix2pix --direction AtoB --gpu 0 --display_id 0\n",
    "\n",
    "bsub -Is -gpu \"num=1:mode=exclusive_process:mps=yes\" python test.py --dataroot /gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing --name cellvision5 --model pix2pix --direction AtoB\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05714369656897892, 0.7171568099233542),\n",
       " (0.038133483581749734, 0.7674732462544108),\n",
       " (0.03288369849270328, 0.7554218806931998),\n",
       " (0.018270039938528673, 0.7620264046911202),\n",
       " (0.0545751440235492, 0.6839410853367558),\n",
       " (0.046952584255868485, 0.7304409837197041),\n",
       " (0.04147598324822782, 0.7056266584132316),\n",
       " (0.01306456762334604, 0.7515882475204598),\n",
       " (0.05609789309534377, 0.691740616354918),\n",
       " (0.02147631863767301, 0.7468515910674022),\n",
       " (0.02376342879878884, 0.7143934339438036),\n",
       " (0.03382621884363293, 0.7376405876895635),\n",
       " (0.018309694071439307, 0.7731926511276043),\n",
       " (0.07481906893185049, 0.6711480014641374),\n",
       " (0.013846834119998977, 0.7492556868119543),\n",
       " (0.0137544923348324, 0.7594305151533425),\n",
       " (0.05010281400588325, 0.7349324320381804),\n",
       " (0.008771227152750456, 0.7557971005435014),\n",
       " (0.01956554404470542, 0.7613542851160797),\n",
       " (0.04235491397497991, 0.7069071956328872),\n",
       " (0.0198487963839545, 0.7619011574941551),\n",
       " (0.06503811806811458, 0.6949993743729708),\n",
       " (0.02291022754750139, 0.6889802910217707),\n",
       " (0.043264449044740756, 0.7023088291580223),\n",
       " (0.03810531606266777, 0.7201191145069467),\n",
       " (0.028572428105055423, 0.7258902815951664),\n",
       " (0.0432649885490839, 0.7568896952500694),\n",
       " (0.047025546299754604, 0.7404546195083562),\n",
       " (0.0792307456139637, 0.6748464289969538),\n",
       " (0.01290609908446827, 0.743346928641182),\n",
       " (0.05934115880133413, 0.6869593283133223),\n",
       " (0.03200044901588304, 0.7451683893003322),\n",
       " (0.020274648268758393, 0.717596427310532),\n",
       " (0.02295653945670972, 0.7821462858800661),\n",
       " (0.038396480079863064, 0.7464594212987865),\n",
       " (0.03355733780399565, 0.7366313311669501),\n",
       " (0.03436284431568626, 0.7097622974078106),\n",
       " (0.04748343742359096, 0.7434260535080035),\n",
       " (0.022153308377527475, 0.7516520510060122),\n",
       " (0.03475298849009369, 0.7919348330541638),\n",
       " (0.05906668816162352, 0.6654269839556836),\n",
       " (0.047610802436562204, 0.6355517986859184),\n",
       " (0.05154525262300212, 0.7515970615689948),\n",
       " (0.03601933399316949, 0.7502819204447794),\n",
       " (0.020795184744546898, 0.7399983633477286),\n",
       " (0.03919260576261427, 0.70843192238638),\n",
       " (0.0319260492951501, 0.7321151832476224),\n",
       " (0.015024931901358377, 0.7677617879426211),\n",
       " (0.04699016194974132, 0.7478244783936664),\n",
       " (0.07021357142601596, 0.6883341674633613),\n",
       " (0.01863040464456008, 0.7103299738507433),\n",
       " (0.04021662839990392, 0.7470606761820451),\n",
       " (0.01939323365331367, 0.7587533859516028),\n",
       " (0.03512579634258443, 0.7403824812642034),\n",
       " (0.04231956535534516, 0.6826332028460975),\n",
       " (0.05995690234881043, 0.698082604029217),\n",
       " (0.018601936576345596, 0.758436596020225),\n",
       " (0.04875312343257555, 0.7269091737207868),\n",
       " (0.014574939092711079, 0.7371738099168464),\n",
       " (0.01300142152853852, 0.6997585405392208),\n",
       " (0.05217425585283575, 0.7290915122353075),\n",
       " (0.05022259502925079, 0.6996872379013911),\n",
       " (0.058850909907007545, 0.7024537474421119),\n",
       " (0.01687819013376934, 0.7596260922084839),\n",
       " (0.04638656243839585, 0.7119447913912846),\n",
       " (0.04963073626551669, 0.7399452652886656),\n",
       " (0.03863111014995213, 0.707504992343106),\n",
       " (0.04304733651323752, 0.6726935106950344),\n",
       " (0.026716725780171046, 0.7437646084848543),\n",
       " (0.032831401220652236, 0.7302173899423147),\n",
       " (0.0175533143572334, 0.7542556927808733),\n",
       " (0.05221646241098813, 0.7679765718315308),\n",
       " (0.012078851445512068, 0.7611220531478339),\n",
       " (0.013630748756730135, 0.727279360199072),\n",
       " (0.01712385485300622, 0.7623632554916847),\n",
       " (0.04574340133644171, 0.7389676514926828),\n",
       " (0.03198618916560126, 0.7271344824344621),\n",
       " (0.017418218357160502, 0.7181426602927462),\n",
       " (0.03548690476080344, 0.756056539387067),\n",
       " (0.05619156278192649, 0.6845201440059019),\n",
       " (0.027691467520660085, 0.7350474439945712),\n",
       " (0.04995427220901576, 0.7271058541542165),\n",
       " (0.025609109512389355, 0.6446351120271536),\n",
       " (0.035063979329328164, 0.7643284118154184),\n",
       " (0.04149472013473669, 0.6638250263109726),\n",
       " (0.027166489372175234, 0.7548418053429228),\n",
       " (0.04386401393855414, 0.7498425973492671),\n",
       " (0.04780104936659028, 0.7048966498437051),\n",
       " (0.02160396903046938, 0.7657280303050841),\n",
       " (0.030589881509023188, 0.7507532612167257),\n",
       " (0.018214935682098816, 0.7331904665216505),\n",
       " (0.03406810564592082, 0.7049771887701893),\n",
       " (0.021660599608146005, 0.6555375778053534),\n",
       " (0.034293642236641095, 0.7156788033682681),\n",
       " (0.019138745712720156, 0.7521588990932885),\n",
       " (0.0476678247682795, 0.6719303438493632),\n",
       " (0.056151068213511714, 0.7114242459670428),\n",
       " (0.02255038104714254, 0.74935046885636),\n",
       " (0.014998382143523123, 0.7024696175912432)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "results_dir = '/home/dg3047/capstone/pytorch-CycleGAN-and-pix2pix/results/cellvision5/test_latest/images'\n",
    "\n",
    "# out_imgs = glob.glob(results_dir)\n",
    "\n",
    "mses = []\n",
    "ssims = []\n",
    "\n",
    "for i in range(1,100):\n",
    "    real_path_low = '{}/{}_real_A.png'.format(results_dir,i)\n",
    "    real_path_high = '{}/{}_real_B.png'.format(results_dir,i)\n",
    "    fake_path = '{}/{}_fake_B.png'.format(results_dir,i)\n",
    "    \n",
    "    real_img_high = color.rgb2gray(io.imread(real_path_high).astype(np.uint))\n",
    "    real_img_low = color.rgb2gray(io.imread(real_path_low).astype(np.uint))\n",
    "    fake_img = color.rgb2gray(io.imread(fake_path).astype(np.uint))\n",
    "    \n",
    "    _min = real_img_high_ft.min()\n",
    "    _max = real_img_high_ft.max()\n",
    "\n",
    "    low_high_ssim = compare_ssim(real_img_low, real_img_high, data_range=_max-_min)\n",
    "    fake_high_ssim = compare_ssim(fake_img, real_img_high, data_range=_max-_min)\n",
    "    ssims.append( (low_high_ssim,fake_high_ssim) )\n",
    "    \n",
    "    low_high_mse = compare_mse(real_img_low, real_img_high)\n",
    "    fake_high_mse = compare_mse(fake_img, real_img_high)\n",
    "    \n",
    "    mses.append( (low_high_mse,fake_high_mse) )\n",
    "\n",
    "\n",
    "ssims[0:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low ssim mean 0.03523206115861787 with std 0.015971007061636254\n",
      "Fake ssim mean 0.7272434952244862 with std 0.03228345536195664\n",
      "\n",
      "Low mse mean 2.9115057547079674e-37 with std 1.7443831171497942e-37\n",
      "Fake mse mean 1.2529523666832592e-38 with std 9.488763181891202e-39\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "low = [ssim[0] for ssim in ssims]\n",
    "low_std = statistics.stdev(low)\n",
    "low_mean = statistics.mean(low)\n",
    "\n",
    "fake = [ssim[1] for ssim in ssims]\n",
    "fake_std = statistics.stdev(fake)\n",
    "fake_mean = statistics.mean(fake)\n",
    "\n",
    "print(\"Low ssim mean {} with std {}\".format(low_mean,low_std))\n",
    "print(\"Fake ssim mean {} with std {}\".format(fake_mean,fake_std))\n",
    "\n",
    "low_mse = [mse[0] for mse in mses]\n",
    "low_std_mse = statistics.stdev(low_mse)\n",
    "low_mean_mse = statistics.mean(low_mse)\n",
    "\n",
    "fake_mse = [mse[1] for mse in mses]\n",
    "fake_std_mse = statistics.stdev(fake_mse)\n",
    "fake_mean_mse = statistics.mean(fake_mse)\n",
    "print()\n",
    "print(\"Low mse mean {} with std {}\".format(low_mean_mse,low_std_mse))\n",
    "print(\"Fake mse mean {} with std {}\".format(fake_mean_mse,fake_std_mse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
