{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pix2Pix modeling\n",
    "\n",
    "Model repo: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1611.07004.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellvision_lib import train_test_val\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/A/test\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/A/train\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/A/val\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/B/test\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/B/train\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/B/val\n",
      "[['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample68_channel1_z93.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample68_channel6_z93.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample57_channel1_z33.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample57_channel6_z33.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample74_channel1_z35.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample74_channel6_z35.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample60_channel1_z97.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample60_channel6_z97.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample59_channel1_z9.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample59_channel6_z9.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample9_channel1_z85.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample9_channel6_z85.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample29_channel1_z42.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample29_channel6_z42.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample114_channel1_z82.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample114_channel6_z82.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample53_channel1_z12.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample53_channel6_z12.tif'], ['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample76_channel1_z54.tif', '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample76_channel6_z54.tif']]\n",
      "0\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample68_channel1_z93.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample68_channel6_z93.tif\n",
      "1\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample57_channel1_z33.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample57_channel6_z33.tif\n",
      "2\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample74_channel1_z35.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample74_channel6_z35.tif\n",
      "3\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample60_channel1_z97.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample60_channel6_z97.tif\n",
      "4\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample59_channel1_z9.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample59_channel6_z9.tif\n",
      "5\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample9_channel1_z85.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample9_channel6_z85.tif\n",
      "6\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample29_channel1_z42.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample29_channel6_z42.tif\n",
      "7\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample114_channel1_z82.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample114_channel6_z82.tif\n",
      "8\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample53_channel1_z12.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample53_channel6_z12.tif\n",
      "9\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample76_channel1_z54.tif\n",
      "/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized/sample76_channel6_z54.tif\n",
      "['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/A/train']\n",
      "['/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/B/train']\n"
     ]
    }
   ],
   "source": [
    "# Proprocesing the data for pix2pix model\n",
    "import os\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "MAX_DEPTH = 100\n",
    "NUM_SAMPLES = 109\n",
    "\n",
    "# folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized'\n",
    "# train, test, val = train_test_val(folder_path, channels = 1, train_pp = .67, test_pp = .165, val_pp = .165, set_seed = 1)\n",
    "\n",
    "# train[0:10]\n",
    "\n",
    "def clear_test_files(pix2pix_path):\n",
    "    outer_paths = ['A','B']\n",
    "    inner_paths = ['test','train','val']\n",
    "    for outer in outer_paths:\n",
    "        for inner in inner_paths:\n",
    "            print('{root}/{split}/{inner}'.format(root=pix2pix_path, split=outer, inner=inner))\n",
    "            files = glob.glob('{root}/{split}/{inner}/*'.format(root=pix2pix_path, split=outer, inner=inner))\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "                \n",
    "def setup_images_for_pix2pix():\n",
    "    pix_folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing'\n",
    "    clear_test_files(pix_folder_path)\n",
    "    folder_path = '/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-normalized'\n",
    "    train, test, val = train_test_val(folder_path, \n",
    "                                      channels = 1, \n",
    "                                      train_pp = .67, \n",
    "                                      test_pp = .165, \n",
    "                                      val_pp = .165, \n",
    "                                      set_seed = 1)\n",
    "    train_images = train[0:10]\n",
    "    test_images = test[0:10]\n",
    "    val_images = val[0:10]\n",
    "    print(train_images)\n",
    "    \n",
    "    for i, (comp, ref) in enumerate(train_images):\n",
    "        print(i)\n",
    "        print(comp)\n",
    "        print(ref)\n",
    "        new_comp_path = pix_folder_path + '/A/train/{}.img'.format(i)\n",
    "        new_ref_path = pix_folder_path + '/B/train/{}.img'.format(i)\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "    \n",
    "    for comp, ref in test_images:\n",
    "        new_comp_path = pix_folder_path + '/A/test/{}.img'.format(i)\n",
    "        new_ref_path = pix_folder_path + '/B/test/{}.img'.format(i)\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "        \n",
    "    for comp, ref in val_images:\n",
    "        new_comp_path = pix_folder_path + '/A/val/{}.img'.format(i)\n",
    "        new_ref_path = pix_folder_path + '/B/val/{}.img'.format(i)\n",
    "        copyfile(comp, new_comp_path)\n",
    "        copyfile(ref, new_ref_path)\n",
    "\n",
    "\n",
    "setup_images_for_pix2pix()\n",
    "print(glob.glob('/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/A/train'))\n",
    "print(glob.glob('/gpfs/data/lionnetlab/cellvision/pilotdata/20181009-pix2pix/testing/B/train'))\n",
    "\n",
    "# print(len(channel1_comps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
